"0908.0980","R Doomun","Syed S. Rizvi, Khaled M. Elleithy, Aasia Riasat","Deterministic Formulization of SNR for Wireless Multiuser DS-CDMA
  Networks","9 pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS July 2009, ISSN 1947 5500, Impact Factor 0.423","International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 3, No. 1, July 2009, USA",,,"cs.NI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Wireless Multiuser receivers suffer from their relatively higher
computational complexity that prevents widespread use of this technique. In
addition, one of the main characteristics of multi-channel communications that
can severely degrade the performance is the inconsistent and low values of SNR
that result in high BER and poor channel capacity. It has been shown that the
computational complexity of a multiuser receiver can be reduced by using the
transformation matrix (TM) algorithm [4]. In this paper, we provide
quantification of SNR based on the computational complexity of TM algorithm. We
show that the reduction of complexity results high and consistent values of SNR
that can consequently be used to achieve a desirable BER performance. In
addition, our simulation results suggest that the high and consistent values of
SNR can be achieved for a desirable BER performance. The performance measure
adopted in this paper is the consistent values of SNR.
","[{""version"":""v1"",""created"":""Sun, 9 Aug 2009 06:57:39 GMT""}]","2009-08-10"
"0908.1161","Herko P. van der Meulen","E. Gallardo, L.J. Martinez, A.K. Nowak, H.P. van der Meulen, J.M.
  Calleja, C. Tejedor, I. Prieto, D. Granados, A.G. Taboada, J.M. Garcia and
  P.A. Postigo","Microcavity-mediated Coupling of Two Distant Semiconductor Qubits","16 pages, 4 figures",,,,"cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Long distance (1.4 micron) interaction of two different InAs/GaAs quantum
dots in a photonic crystal microcavity is observed. Resonant optical excitation
in the p-state of any of the quantum dots, results in an increase of the
s-state emission of both quantum dots and the cavity mode. The cavity-mediated
coupling can be controlled by varying the excitation intensity. These results
represent an experimental step towards the realization of quantum logic
operations using distant solid state qubits.
","[{""version"":""v1"",""created"":""Sun, 9 Aug 2009 00:26:22 GMT""}]","2009-08-11"
"0908.1169","Karin \""Oberg","K. I. Oberg, R. T. Garrod, E. F. van Dishoeck and H. Linnartz","Formation rates of complex organics in UV irradiated CH3OH-rich ices I:
  Experiments","Accepted for publication in A&A. 65 pages including appendices",,"10.1051/0004-6361/200912559",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  (Abridged) Gas-phase complex organic molecules are commonly detected in the
warm inner regions of protostellar envelopes. Recent models show that
photochemistry in ices followed by desorption may explain the observed
abundances. This study aims to experimentally quantify the broad-band
UV-induced production rates of complex organics in CH3OH-rich ices at 20-70 K
under ultra-high vacuum conditions. The reaction products are mainly identified
by RAIRS and TPD experiments. Complex organics are readily formed in all
experiments, both during irradiation and during a slow warm-up of the ices to
200 K after the UV lamp is turned off. The relative abundances of photoproducts
depend on the UV fluence, the ice temperature, and whether pure CH3OH ice or
CH3OH:CH4/CO ice mixtures are used. C2H6, CH3CHO, CH3CH2OH, CH3OCH3, HCOOCH3,
HOCH2CHO and (CH2OH)2 are all detected in at least one experiment. The derived
product-formation yields and their dependences on different experimental
parameters, such as the initial ice composition, are used to estimate the CH3OH
photodissociation branching ratios in ice and the relative diffusion barriers
of the formed radicals. The experiments show that ice photochemistry in CH3OH
ices is efficient enough to explain the observed abundances of complex organics
around protostars and that ratios of complex molecules can be used to constrain
their formation pathway.
","[{""version"":""v1"",""created"":""Sat, 8 Aug 2009 23:21:33 GMT""}]","2015-05-13"
"0908.1174","Christopher Smith","Jernej F. Kamenik and Christopher Smith","Tree-level contributions to the rare decays B+ --> pi+ nu anti-nu, B+
  --> K+ nu anti-nu, and B+ --> K*+ nu anti-nu in the Standard Model","5 pages, 6 figures","Phys.Lett.B680:471-475,2009","10.1016/j.physletb.2009.09.041",,"hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The tree-level contributions to the rare decays B+ --> pi+ nu anti-nu, B+ -->
K+ nu anti-nu, and B+ --> K*+ nu anti-nu are analyzed and compared to those
occurring in K+ --> pi+ nu anti-nu, D+ --> pi+ nu anti-nu, and Ds+ --> pi+ nu
anti-nu. It is shown that these purely long-distance contributions, arising
from the exchange of a charged lepton, can be significant in B+ decays for an
intermediate tau, potentially blurring the distinction between the modes used
to extract B --> tau nu and those used to probe the genuine short-distance b
--> (s,d) nu anti-nu FCNC transitions. Numerically, the tree-level
contributions are found to account for 97%, 12% and 14% of the total B+ --> pi+
nu anti-nu, B+ --> K+ nu anti-nu, and B+ --> K*+ nu anti-nu rates,
respectively.
","[{""version"":""v1"",""created"":""Sat, 8 Aug 2009 16:01:04 GMT""}]","2009-10-29"
"0908.1175","Joeri van Leeuwen","Joeri van Leeuwen, the ATA team","The Allen Telescope Array: The First Widefield, Panchromatic, Snapshot
  Radio Camera","Invited review, proceedings of the ""Panoramic Radio Astronomy:
  Wide-field 1-2 GHz research on galaxy evolution"" meeting in Groningen, the
  Netherlands, June 2009. 8 Pages",,,,"astro-ph.IM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The first 42 elements of the Allen Telescope Array (ATA-42) are beginning to
deliver data at the Hat Creek Radio Observatory in Northern California.
Scientists and engineers are actively exploiting all of the flexibility
designed into this innovative instrument for simultaneously conducting
panoramic surveys of the astrophysical sky. The fundamental scientific program
of this new telescope is varied and exciting; we here discuss some of the first
astronomical results.
","[{""version"":""v1"",""created"":""Sat, 8 Aug 2009 16:42:30 GMT""}]","2009-08-11"
"0908.1176","Marco Padovani","M. Padovani (1 and 2), C. M. Walmsley (2), M. Tafalla (3), D. Galli
  (2) and H. S. P. M\""uller (4) ((1) Universit\`a di Firenze, Dipartimento di
  Astronomia e Scienza dello Spazio, Firenze, Italy, (2) INAF-Osservatorio
  Astrofisico di Arcetri, Firenze, Italy, (3) Observatorio Astron\'omico
  Nacional, Madrid, Spain, (4) I. Physikalisches Institut, Universit\""at zu
  K\""oln, K\""oln, Germany)","CCH in prestellar cores","14 pages, 13 figures, to be published in Astronomy and Astrophysics","Astron. Astrophys. 505 (2009) 1199 - 1211","10.1051/0004-6361/200912547",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the abundance of CCH in prestellar cores both because of its role in
the chemistry and because it is a potential probe of the magnetic field. We
also consider the non-LTE behaviour of the N=1-0 and N=2-1 transitions of CCH
and improve current estimates of the spectroscopic constants of CCH. We used
the IRAM 30m radiotelescope to map the N=1-0 and N=2-1 transitions of CCH
towards the prestellar cores L1498 and CB246. Towards CB246, we also mapped the
1.3 mm dust emission, the J=1-0 transition of N2H+ and the J=2-1 transition of
C18O. We used a Monte Carlo radiative transfer program to analyse the CCH
observations of L1498. We derived the distribution of CCH column densities and
compared with the H2 column densities inferred from dust emission. We find that
while non-LTE intensity ratios of different components of the N=1-0 and N=2-1
lines are present, they are of minor importance and do not impede CCH column
density determinations based upon LTE analysis. Moreover, the comparison of our
Monte-Carlo calculations with observations suggest that the non-LTE deviations
can be qualitatively understood. For L1498, our observations in conjunction
with the Monte Carlo code imply a CCH depletion hole of radius 9 x 10^{16} cm
similar to that found for other C-containing species. We briefly discuss the
significance of the observed CCH abundance distribution. Finally, we used our
observations to provide improved estimates for the rest frequencies of all six
components of the CCH(1-0) line and seven components of CCH(2-1). Based on
these results, we compute improved spectroscopic constants for CCH. We also
give a brief discussion of the prospects for measuring magnetic field strengths
using CCH.
","[{""version"":""v1"",""created"":""Sat, 8 Aug 2009 17:20:01 GMT""}]","2016-11-23"
"0908.1179","Anatoly Smirnov","Anatoly Yu. Smirnov, Sergey E. Savel'ev, and Franco Nori","Diffusion-controlled generation of a proton-motive force across a
  biomembrane","26 pages, 4 figures. A similar model is used in arXiv:0806.3233 for a
  different biological system. Minor changes in the Acknowledgements section","Phys. Rev. E 80, 011916 (2009)","10.1103/PhysRevE.80.011916",,"physics.bio-ph cond-mat.soft q-bio.SC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Respiration in bacteria involves a sequence of energetically-coupled electron
and proton transfers creating an electrochemical gradient of protons (a
proton-motive force) across the inner bacterial membrane. With a simple kinetic
model we analyze a redox loop mechanism of proton-motive force generation
mediated by a molecular shuttle diffusing inside the membrane. This model,
which includes six electron-binding and two proton-binding sites, reflects the
main features of nitrate respiration in E. coli bacteria. We describe the time
evolution of the proton translocation process. We find that the electron-proton
electrostatic coupling on the shuttle plays a significant role in the process
of energy conversion between electron and proton components. We determine the
conditions where the redox loop mechanism is able to translocate protons
against the transmembrane voltage gradient above 200 mV with a thermodynamic
efficiency of about 37%, in the physiologically important range of temperatures
from 250 to 350 K.
","[{""version"":""v1"",""created"":""Sun, 9 Aug 2009 13:36:08 GMT""},{""version"":""v2"",""created"":""Fri, 4 Dec 2009 02:44:03 GMT""}]","2015-05-13"
"0908.1180","Marian Ioan Munteanu Dr","Franki Dillen and Marian Ioan Munteanu and Joeri Van der Veken and Luc
  Vrancken","Constant Angle Surfaces in a warped product","12 pages","Balkan Journal of Geometry and Its Applications, 16 (2011) 2, 35 -
  47",,,"math.DG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let $I \subseteq \R$ be an open interval, $f : I \to \R$ a strictly positive
function and denote by $\E^2$ the Euclidean plane. We classify all surfaces in
the warped product manifold $I \times_f \E^2$ for which the unit normal makes a
constant angle with the direction tangent to $I$.
","[{""version"":""v1"",""created"":""Sat, 8 Aug 2009 18:17:39 GMT""}]","2011-06-21"
"0908.1181","Vijay  Vazirani","Vijay V. Vazirani","2-Player Nash and Nonsymmetric Bargaining Games: Algorithms and
  Structural Properties",,,"10.1007/978-3-642-16170-4_28",,"cs.GT cs.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The solution to a Nash or a nonsymmetric bargaining game is obtained by
maximizing a concave function over a convex set, i.e., it is the solution to a
convex program. We show that each 2-player game whose convex program has linear
constraints, admits a rational solution and such a solution can be found in
polynomial time using only an LP solver. If in addition, the game is succinct,
i.e., the coefficients in its convex program are ``small'', then its solution
can be found in strongly polynomial time. We also give a non-succinct linear
game whose solution can be found in strongly polynomial time.
","[{""version"":""v1"",""created"":""Sun, 9 Aug 2009 01:52:35 GMT""},{""version"":""v2"",""created"":""Fri, 14 Aug 2009 05:04:35 GMT""},{""version"":""v3"",""created"":""Thu, 24 Sep 2009 21:35:32 GMT""}]","2015-05-13"
"0908.1182","Brian DeMarco","M. Pasienski, D. McKay, M. White, and B. DeMarco","Disordered insulator in an optical lattice",,,"10.1038/nphys1726",,"cond-mat.quant-gas cond-mat.dis-nn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Disorder can profoundly affect the transport properties of a wide range of
quantum materials. Presently, there is significant disagreement regarding the
effect of disorder on transport in the disordered Bose-Hubbard (DBH) model,
which is the paradigm used to theoretically study disorder in strongly
correlated bosonic systems. We experimentally realize the DBH model by using
optical speckle to introduce precisely known, controllable, and fine-grained
disorder to an optical lattice5. Here, by measuring the dissipation strength
for transport, we discover a disorder-induced SF-to-insulator (IN) transition
in this system, but we find no evidence for an IN-to-SF transition. Emergence
of the IN at disorder strengths several hundred times the tunnelling energy
agrees with a predicted SF--Bose glass (BG) transition from recent quantum
Monte Carlo (QMC) work. Both the SF--IN transition and correlated changes in
the atomic quasimomentum distribution--which verify a simple model for the
interplay of disorder and interactions in this system--are phenomena new to the
unit filling regime explored in this work, compared with the high filling limit
probed previously. We find that increasing disorder strength generically leads
to greater dissipation in the regime of mixed SF and Mott-insulator (MI)
phases, excluding predictions of a disorder-induced, or ""re-entrant,"" SF (RSF).
While the absence of an RSF may be explained by the effect of finite
temperature, we strongly constrain theories by measuring bounds on the entropy
per particle in the disordered lattice.
","[{""version"":""v1"",""created"":""Sat, 8 Aug 2009 18:57:16 GMT""},{""version"":""v2"",""created"":""Sun, 27 Dec 2009 05:29:38 GMT""}]","2015-05-13"
"0908.1183","Vladimir Popov L","Vladimir L. Popov","Algebraic cones","3 pages","Math. Notes 86 (2009), no. 6, 892--894",,,"math.AG math.AC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A characterization of algebraic cones in terms of actions of the
one-dimensional multiplicative algebraic monoid ${\bf M}_{\rm m}$ and the
algebraic group ${\bf G}_{\rm m}$ are given.
","[{""version"":""v1"",""created"":""Sat, 8 Aug 2009 18:58:44 GMT""}]","2011-10-26"
"0908.1184","Tao Zhou","Yu-Han Chen, Bing-Hong Wang, Li-Chao Zhao, Changsong Zhou, Tao Zhou","Optimal transport on supply-demand networks","5 pages, 1 table and 4 figures","Physical Review E 81, 066105 (2010)","10.1103/PhysRevE.81.066105",,"physics.data-an physics.soc-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Previously, transport networks are usually treated as homogeneous networks,
that is, every node has the same function, simultaneously providing and
requiring resources. However, some real networks, such as power grid and supply
chain networks, show a far different scenario in which the nodes are classified
into two categories: the supply nodes provide some kinds of services, while the
demand nodes require them. In this paper, we propose a general transport model
for those supply-demand networks, associated with a criterion to quantify their
transport capacities. In a supply-demand network with heterogenous degree
distribution, its transport capacity strongly depends on the locations of
supply nodes. We therefore design a simulated annealing algorithm to find the
optimal configuration of supply nodes, which remarkably enhances the transport
capacity, and outperforms the degree target algorithm, the betweenness target
algorithm, and the greedy method. This work provides a start point for
systematically analyzing and optimizing transport dynamics on supply-demand
networks.
","[{""version"":""v1"",""created"":""Sat, 8 Aug 2009 19:51:05 GMT""}]","2010-06-08"
"0908.1185","Carlos Javier Hernandez-Castro","Carlos Javier Hernandez-Castro, Arturo Ribagorda, Yago Saez","Side-channel attack on labeling CAPTCHAs",,,,,"cs.CR cs.CV cs.CY cs.HC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose a new scheme of attack on the Microsoft's ASIRRA CAPTCHA which
represents a significant shortcut to the intended attacking path, as it is not
based in any advance in the state of the art on the field of image recognition.
After studying the ASIRRA Public Corpus, we conclude that the security margin
as stated by their authors seems to be quite optimistic. Then, we analyze which
of the studied parameters for the image files seems to disclose the most
valuable information for helping in correct classification, arriving at a
surprising discovery. This represents a completely new approach to breaking
CAPTCHAs that can be applied to many of the currently proposed image-labeling
algorithms, and to prove this point we show how to use the very same approach
against the HumanAuth CAPTCHA. Lastly, we investigate some measures that could
be used to secure the ASIRRA and HumanAuth schemes, but conclude no easy
solutions are at hand.
","[{""version"":""v1"",""created"":""Sat, 8 Aug 2009 19:54:01 GMT""}]","2009-08-11"
"0908.1186","Grenville Croll","Patrick O'Beirne","Checks and Controls in Spreadsheets","7 Pages","Proc. European Spreadsheet Risks Int. Grp. (EuSpRIG) 2009 1-7 ISBN
  978-1-905617-89-0",,,"cs.HC cs.SE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Spreadsheets that are informally created are harder to test than they should
be. Simple cross-foot checks or being easily readable are modest but attainable
goals for every spreadsheet developer. This paper lists some tips on building
self-checking into a spreadsheet in order to provide more confidence to the
reader that a spreadsheet is robust.
","[{""version"":""v1"",""created"":""Sat, 8 Aug 2009 20:38:12 GMT""}]","2009-08-11"
"0908.1187","Grenville Croll","Jocelyn Paine","Documenting Spreadsheets with Pseudo-Code: an Exercise with Cash-Flow
  and Loans","12 Pages","Proc. European Spreadsheet Risks Int. Grp. (EuSpRIG) 2009 173-183
  ISBN 978-1-905617-89-0",,,"cs.SE cs.HC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  ""Look before you leap""; ""a stitch in time saves nine""; ""more haste, less
speed"". Many proverbs declare the wisdom of planning before doing. We suggest
how to apply this to Excel, by explaining and specifying spreadsheets before
coding them, so there will always be documentation for auditors and maintenance
programmers. The specification method uses ""pseudo-code"": code that, for
precision and conciseness, resembles a programming language, but is not
executable. It is, however, based on the notation used by our Excelsior
spreadsheet generator, which is executable. This paper is structured as a
tutorial, in which we develop a simple cash-flow and loans spreadsheet.
","[{""version"":""v1"",""created"":""Sat, 8 Aug 2009 20:44:50 GMT""}]","2009-08-11"
"0908.1188","Grenville Croll","Thomas A. Grossman, Ozgur Ozluk, Jan Gustavson","The Lookup Technique to Replace Nested-IF Formulas in Spreadsheet
  Programming","10 Pages, 5 Figures; ISBN 978-1-905617-89-0","Proc. European Spreadsheet Risks Int. Grp. (EuSpRIG) 2009 17-26",,,"cs.SE cs.HC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Spreadsheet programmers often implement contingent logic using a nested-IF
formula even though this technique is difficult to test and audit and is
believed to be risky. We interpret the programming of contingent logic in
spreadsheets in the context of traditional computer programming. We investigate
the ""lookup technique"" as an alternative to nested-IF formulas, describe its
benefits for testing and auditing, and define its limitations. The lookup
technique employs four distinct principles: 1) make logical tests visible; 2)
make outcomes visible; 3) make logical structure visible; and 4) replace a
multi-function nested-IF formula with a single-function lookup formula. It can
be used only for certain simple contingent logic. We describe how the
principles can be applied in more complex situations, and suggest avenues for
further research.
","[{""version"":""v1"",""created"":""Sat, 8 Aug 2009 20:53:04 GMT""}]","2011-02-19"
"0908.1189","Grenville Croll","Etienne Vandeput","Milestones for Teaching the Spreadsheet Program","11 Pages","Proc. European Spreadsheet Risks Int. Grp. (EuSpRIG) 2009 133-143
  ISBN 978-1-905617-89-0",,,"cs.HC cs.LO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  There are different manners of teaching a spreadsheet program. In any case,
it is intended that the teacher settles the objectives of the course and adapts
them to the particular audience he/she has to deal with. This paper aims at
providing any teacher whatever his/her specific objectives and his/her audience
with elements to help him/her building a course. It focuses mainly on two
important issues: 1 - select in all that may be said about such complex tools,
what is prior to know and to teach, i.e. what leads to autonomy in using but
also to autonomy in learning (because everything cannot be taught) and 2 - show
how concepts are closely related to good formatting considerations. A method
based on the ""invariants of information processing"" is outlined, partially
illustrated and an implementation is described throughout a course designed for
students preparing a master in Education Sciences.
","[{""version"":""v1"",""created"":""Sat, 8 Aug 2009 21:02:41 GMT""}]","2009-08-11"
"0908.1190","Grenville Croll","Leslie Bradley, Kevin McDaid","Error Estimation in Large Spreadsheets using Bayesian Statistics","12 Pages, 5 Colour Figures","Proc. European Spreadsheet Risks Int. Grp. (EuSpRIG) 2009 27-38
  ISBN 978-1-905617-89-0",,,"cs.SE cs.HC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Spreadsheets are ubiquitous in business with the financial sector
particularly heavily reliant on the technology. It is known that the level of
spreadsheet error can be high and that it is often necessary to review
spreadsheets based on a structured methodology which includes a cell by cell
examination of the spreadsheet. This paper outlines the early research that has
been carried out into the use of Bayesian Statistical methods to estimate the
level of error in large spreadsheets during cell be cell examination based on
expert knowledge and partial spreadsheet test data. The estimate can aid in the
decision as to the quality of the spreadsheet and the necessity to conduct
further testing or not.
","[{""version"":""v1"",""created"":""Sat, 8 Aug 2009 21:08:53 GMT""}]","2009-08-11"
"0908.1191","Grenville Croll","Angela Collins","Embedded Spreadsheet Modelling","5 Pages","Proc. European Spreadsheet Risks Int. Grp. (EuSpRIG) 2009 95-99
  ISBN 978-1-905617-89-0",,,"cs.HC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In larger accounting firms, specialist modellers typically sit in separate
teams. This paper will look at the advantages of embedding a specialist
modeller within a Corporate Finance Team.
","[{""version"":""v1"",""created"":""Sat, 8 Aug 2009 21:13:27 GMT""}]","2009-08-11"
"0908.1192","Grenville Croll","Matthew Dinmore","Documenting Problem-Solving Knowledge: Proposed Annotation Design
  Guidelines and their Application to Spreadsheet Tools","12 Pages, 4 Figures","Proc. European Spreadsheet Risks Int. Grp. (EuSpRIG) 2009 57-68
  ISBN 978-1-905617-89-0",,,"cs.SE cs.HC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  End-user programmers create software to solve problems, yet the
problem-solving knowledge generated in the process often remains tacit within
the software artifact. One approach to exposing this knowledge is to enable the
end-user to annotate the artifact as they create and use it. A 3-level model of
annotation is presented and guidelines are proposed for the design of end-user
programming environments supporting the explicit and literate annotation
levels. These guidelines are then applied to the spreadsheet end-user
programming paradigm.
","[{""version"":""v1"",""created"":""Sat, 8 Aug 2009 21:18:31 GMT""}]","2009-08-11"
"0908.1193","Grenville Croll","Derek Flood, Kevin Mc Daid, Fergal Mc Caffery","NLP-SIR: A Natural Language Approach for Spreadsheet Information
  Retrieval","12 Pages, 2 Colour Figures, 3 Tables","Proc. European Spreadsheet Risks Int. Grp. (EuSpRIG) 2009 101-112
  ISBN 978-1-905617-89-0",,,"cs.SE cs.HC cs.IR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Spreadsheets are a ubiquitous software tool, used for a wide variety of tasks
such as financial modelling, statistical analysis and inventory management.
Extracting meaningful information from such data can be a difficult task,
especially for novice users unfamiliar with the advanced data processing
features of many spreadsheet applications. We believe that through the use of
Natural Language Processing (NLP) techniques this task can be made considerably
easier. This paper introduces NLP-SIR, a Natural language interface for
spreadsheet information retrieval. The results of a recent evaluation which
compared NLP-SIR with existing Information retrieval tools are also outlined.
This evaluation has shown that NLP-SIR is a more effective method of
spreadsheet information retrieval.
","[{""version"":""v1"",""created"":""Sat, 8 Aug 2009 21:23:52 GMT""}]","2009-08-11"
"0908.1194","Masahito Yamazaki","Mina Aganagic, Hirosi Ooguri, Cumrun Vafa and Masahito Yamazaki","Wall Crossing and M-theory","19 pages, 1 figure","Publ.Res.Inst.Math.Sci.Kyoto 47:569,2011","10.2977/PRIMS/44","CALT-68-2746, IPMU09-0091, UT-09-18","hep-th math.AG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study BPS bound states of D0 and D2 branes on a single D6 brane wrapping a
Calabi-Yau 3-fold X. When X has no compact 4-cyles, the BPS bound states are
organized into a free field Fock space, whose generators correspond to BPS
states of spinning M2 branes in M-theory compactified down to 5 dimensions by a
Calabi-Yau 3-fold X. The generating function of the D-brane bound states is
expressed as a reduction of the square of the topological string partition
function, in all chambers of the Kahler moduli space.
","[{""version"":""v1"",""created"":""Sat, 8 Aug 2009 21:32:54 GMT""}]","2011-07-14"
"0908.1195","Petr Nicolaevich Bibikov","P. N. Bibikov, L. V. Prokhorov","A model with generalized Y-junction","7 pages",,,,"math-ph math.MP quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Klein-Fock-Gordon equation is studied on the generalized Y-junction of
$N$ strings with a massive center. The corresponding formulas for wave
scattering and normal modes are obtained.
","[{""version"":""v1"",""created"":""Sat, 8 Aug 2009 21:50:43 GMT""}]","2009-08-11"
"0908.1196","Karen Yagdjian","Anahit Galstian, Tamotu Kinoshita, and Karen Yagdjian","A Note on Wave Equation in Einstein & de Sitter Spacetime",,"J.Math.Phys.51:052501,2010","10.1063/1.3387249",,"math-ph math.AP math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the wave propagating in the Einstein & de Sitter spacetime. The
covariant d'Alembert's operator in the Einstein & de Sitter spacetime belongs
to the family of the non-Fuchsian partial differential operators. We introduce
the initial value problem for this equation and give the explicit
representation formulas for the solutions. We also show the $L^p - L^q$
estimates for solutions.
","[{""version"":""v1"",""created"":""Sat, 8 Aug 2009 22:08:03 GMT""},{""version"":""v2"",""created"":""Sat, 27 Feb 2010 16:41:16 GMT""}]","2010-09-20"
"0908.1197","Rodney James","Rodney James and Rick Miranda","A Riemann-Roch theorem for edge-weighted graphs","Minor revisions, 10 pages","Proc. Amer. Math. Soc. 141 (2013), 3793-3802","10.1090/S0002-9939-2013-11671-0",,"math.AG math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We prove a Riemann-Roch theorem for real divisors on edge-weighted graphs
over the reals, extending the result of Baker and Norine for integral divisors
on graphs with multiple edges.
","[{""version"":""v1"",""created"":""Sat, 8 Aug 2009 22:13:51 GMT""},{""version"":""v2"",""created"":""Wed, 30 Mar 2011 02:56:23 GMT""},{""version"":""v3"",""created"":""Fri, 27 Jan 2012 01:54:05 GMT""}]","2017-11-13"
"0908.1198","Andrei Maimistov","Ildar R. Gabitov, Bridget Kennedy, Andrei I. Maimistov","Coherent Amplification of Optical Pulses in Metamaterials","9 pages, 5 figures, submitted to IEEE Trans",,"10.1109/JSTQE.2009.2032667",,"nlin.PS nlin.AO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we theoretically study propagation of steady state ultrashort
pulse in dissipative medium. We considered two cases (i) medium consists of
lossy metallic nanostructures embedded into a gain material and (ii) the gain
material is embedded directly into the nanostructures. We found the shape and
velocity of an optical pulse coupled with the polarization wave.
","[{""version"":""v1"",""created"":""Sat, 8 Aug 2009 22:50:41 GMT""}]","2016-11-18"
"0908.1199","Sumedha","Sumedha, Michael F Hagan, Bulbul Chakraborty","Prolonging assembly through dissociation:A self assembly paradigm in
  microtubules","accepted for publication in Physical Review E","Phys. Rev. E 83, 051904 (2011)","10.1103/PhysRevE.83.051904",,"q-bio.BM cond-mat.stat-mech q-bio.SC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study a one-dimensional model of microtubule assembly/disassembly in which
GTP bound to tubulins within the microtubule undergoes stochastic hydrolysis.
In contrast to models that only consider a cap of GTP-bound tubulin, stochastic
hydrolysis allows GTP-bound tubulin remnants to exist within the microtubule.
We find that these buried GTP remnants enable an alternative mechanism of
recovery from shrinkage, and enhances fluctuations of filament lengths. Under
conditions for which this alternative mechanism dominates, an increasing
depolymerization rate leads to a decrease in dissociation rate and thus a net
increase in assembly.
","[{""version"":""v1"",""created"":""Sun, 9 Aug 2009 01:10:49 GMT""},{""version"":""v2"",""created"":""Wed, 13 Apr 2011 08:23:59 GMT""}]","2015-05-13"
"0908.1200","Bradley Chase","Bradley A. Chase","Parameter Estimation, Model Reduction and Quantum Filtering","254 pages, dissertation as submitted to the University of New Mexico,
  August 2009",,,,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This dissertation explores the topics of parameter estimation and model
reduction in the context of quantum filtering. Chapters 2 and 3 provide a
review of classical and quantum probability theory, stochastic calculus and
filtering. Chapter 4 studies the problem of quantum parameter estimation and
introduces the quantum particle filter as a practical computational method for
parameter estimation via continuous measurement. Chapter 5 applies these
techniques in magnetometry and studies the estimator's uncertainty scalings in
a double-pass atomic magnetometer. Chapter 6 presents an efficient feedback
controller for continuous-time quantum error correction. Chapter 7 presents an
exact model of symmetric processes of collective qubit systems.
","[{""version"":""v1"",""created"":""Sat, 8 Aug 2009 23:35:12 GMT""}]","2009-08-11"
"0908.1201","C{\ba}t{\ba}lin C\^arstea","Catalin I. Carstea","A construction of blow up solutions for co-rotational wave maps",,,"10.1007/s00220-010-1118-4",,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The existence of co-rotational finite time blow up solutions to the wave map
problem from R^{2+1} into N, where N is a surface of revolution with metric
d\rho^2+g(\rho)^2 d\theta^2, g an entire function, is proven. These are of the
form u(t,r)=Q(\lambda(t)t)+R(t,r), where Q is a time independent solution of
the co-rotational wave map equation -u_{tt}+u_{rr}+r^{-1}u_r=r^{-2}g(u)g'(u),
\lambda(t)=t^{-1-\nu}, \nu>1/2 is arbitrary, and R is a term whose local energy
goes to zero as t goes to 0.
","[{""version"":""v1"",""created"":""Sun, 9 Aug 2009 00:33:28 GMT""}]","2015-05-13"
"0908.1202","Karimbergen Kudaybergenov","Shavkat A. Ayupov and Karimbergen K. Kudaybergenov","Additive derivations on algebras of measurable operators",,,,,"math.OA math.FA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Given a von Neumann algebra $M$ we introduce so called central extension
$mix(M)$ of $M$. We show that
  $mix(M)$ is a *-subalgebra in the algebra $LS(M)$ of all locally measurable
operators with respect to $M,$ and this algebra coincides with $LS(M)$ if and
only if $M $ does not admit type II direct summands. We prove that if $M$ is a
properly infinite von Neumann algebra then every additive derivation on the
algebra $mix(M)$ is inner. This implies that on the algebra $LS(M)$, where $M$
is a type I$_\infty$ or a type III von Neumann algebra, all additive
derivations are inner derivations.
","[{""version"":""v1"",""created"":""Sun, 9 Aug 2009 01:00:58 GMT""}]","2009-08-11"
"0908.1203","Karimbergen Kudaybergenov","Sh.A. Ayupov, R.Z. Abdullaev, K.K. Kudaybergenov","On a certain class of operator algebras and their derivations",,,,,"math.OA math.FA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Given a von Neumann algebra $M$ with a faithful normal finite trace, we
introduce the so called finite tracial algebra $M_f$ as the intersection of
$L_p$-spaces $L_p(M, \mu)$ over all $p \geq 1$ and over all faithful normal
finite traces $\mu$ on $M.$ Basic algebraic and topological properties of
finite tracial algebras are studied. We prove that all derivations on these
algebras are inner.
","[{""version"":""v1"",""created"":""Sun, 9 Aug 2009 01:11:41 GMT""}]","2009-08-11"
"0908.1205","Zachary Treisman","Zachary Treisman","A young person's guide to the Hopf fibration","43 pages, 17 figures. Comments welcome",,,,"math.HO math.AT","http://creativecommons.org/licenses/by-nc-sa/3.0/","  These notes were used for a two week summer course on the Hopf fibration
taught to high school students.
","[{""version"":""v1"",""created"":""Sun, 9 Aug 2009 01:32:39 GMT""}]","2009-08-11"
"0908.1206","Nathaniel Bowden","N. S. Bowden, P. Marleau, J. T. Steele, S. Mrowka, G. Aigeldinger, W.
  Mengesha","Improved Fast Neutron Spectroscopy via Detector Segmentation","Accepted for publication in Nuclear Instruments and Methods in
  Physics Research Section A","Nucl.Instrum.Meth.A609:32-37,2009","10.1016/j.nima.2009.07.061",,"physics.ins-det","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Organic scintillators are widely used for fast neutron detection and
spectroscopy. Several effects complicate the interpretation of results from
detectors based upon these materials. First, fast neutrons will often leave a
detector before depositing all of their energy within it. Second, fast neutrons
will typically scatter several times within a detector, and there is a
non-proportional relationship between the energy of, and the scintillation
light produced by, each individual scatter; therefore, there is not a
deterministic relationship between the scintillation light observed and the
neutron energy deposited. Here we demonstrate a hardware technique for reducing
both of these effects. Use of a segmented detector allows for the
event-by-event correction of the light yield non-proportionality and for the
preferential selection of events with near-complete energy deposition, since
these will typically have high segment multiplicities.
","[{""version"":""v1"",""created"":""Sun, 9 Aug 2009 01:36:23 GMT""}]","2009-10-29"
"0908.1207","Yan Kagan","Yan Y. Kagan","Earthquake Size Distribution: Power-Law with Exponent Beta = 1/2?","46 pages, 2 tables, 11 figures 53 pages, 2 tables, 12 figures","Tectonophysics, 490(1-2), 103-114, 2010","10.1016/j.tecto.2010.04.034",,"physics.geo-ph physics.data-an","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose that the widely observed and universal Gutenberg-Richter relation
is a mathematical consequence of the critical branching nature of earthquake
process in a brittle fracture environment. These arguments, though preliminary,
are confirmed by recent investigations of the seismic moment distribution in
global earthquake catalogs and by the results on the distribution in crystals
of dislocation avalanche sizes. We consider possible systematic and random
errors in determining earthquake size, especially its seismic moment. These
effects increase the estimate of the parameter beta of the power-law
distribution of earthquake sizes. In particular, we find that estimated
beta-values may be inflated by 1-3% because relative moment uncertainties
decrease with increasing earthquake size. Moreover, earthquake clustering
greatly influences the beta-parameter. If clusters (aftershock sequences) are
taken as the entity to be studied, then the exponent value for their size
distribution would decrease by 5-10%. The complexity of any earthquake source
also inflates the estimated beta-value by at least 3-7%. The centroid depth
distribution also should influence the beta-value, an approximate calculation
suggests that the exponent value may be increased by 2-6%. Taking all these
effects into account, we propose that the recently obtained beta-value of 0.63
could be reduced to about 0.52--0.56: near the universal constant value (1/2)
predicted by theoretical arguments. We also consider possible consequences of
the universal beta-value and its relevance for theoretical and practical
understanding of earthquake occurrence in various tectonic and Earth structure
environments. Using comparative crystal deformation results may help us
understand the generation of seismic tremors and slow earthquakes and
illuminate the transition from brittle fracture to plastic flow.
","[{""version"":""v1"",""created"":""Sun, 9 Aug 2009 01:48:09 GMT""},{""version"":""v2"",""created"":""Thu, 18 Mar 2010 00:00:09 GMT""}]","2015-03-13"
"0908.1208","Seyed Abolfazl Motahari","Abolfazl S. Motahari, Shahab Oveis Gharan, and Amir K. Khandani","Real Interference Alignment with Real Numbers","Submitted to IEEE Trans. on Information Theory",,,,"cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A novel coding scheme applicable in networks with single antenna nodes is
proposed. This scheme converts a single antenna system to an equivalent
Multiple Input Multiple Output (MIMO) system with fractional dimensions.
Interference can be aligned along these dimensions and higher Multiplexing
gains can be achieved. Tools from the field of Diophantine approximation in
number theory are used to show that the proposed coding scheme in fact mimics
the traditional schemes used in MIMO systems where each data stream is sent
along a direction and alignment happens when several streams arrive at the same
direction. Two types of constellation are proposed for the encoding part,
namely the single layer constellation and the multi-layer constellation.
  Using the single layer constellation, the coding scheme is applied to the
two-user $X$ channel and the three-user Gaussian Interference Channel (GIC). In
case of the two-user $X$ channel, it is proved that the total
Degrees-of-Freedom (DOF), i.e. 4/3, of the channel is achievable almost surely.
This is the first example in which it is shown that a time invariant single
antenna system does not fall short of achieving its total DOF.
  Using the multi-layer constellation, the coding scheme is applied to the
symmetric three-user GIC. Achievable DOFs are derived for all channel gains. As
a function of the channel gain, it is observed that the DOF is everywhere
discontinuous.
","[{""version"":""v1"",""created"":""Sun, 9 Aug 2009 05:27:44 GMT""},{""version"":""v2"",""created"":""Wed, 12 Aug 2009 10:00:59 GMT""}]","2009-08-12"
"0908.1212","Earnest Akofor","E. Akofor","Generation and propagation of a q-deformed type of $d^N\neq0$ curvature","6 pages, v2: a few lines added, v3: a typo corrected",,,"SU-4252-896","math-ph gr-qc hep-th math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present an expression for curvature with q-deformed calculus such as
considered in \cite{d-k,b-b-k,f-m-r-s-w}. By exploiting the persistence of
Bianchi's second identity, we suggest a way to attach physical meaning to the
$q$ parameters and $d^N\neq 0$ condition by introducing a physical current, an
example of which may be obtained by a procedure outlined in \cite{akofor}.
","[{""version"":""v1"",""created"":""Sun, 9 Aug 2009 02:32:19 GMT""},{""version"":""v2"",""created"":""Wed, 12 Aug 2009 15:25:20 GMT""}]","2009-08-12"
"0908.1214","Ahmad Sheykhi","Ahmad Sheykhi","Brane-Bulk energy exchange and agegraphic dark energy","13 pages, to appear in IJMPD","Int.J.Mod.Phys.D19:305-316,2010","10.1142/S0218271810016427",,"gr-qc","http://creativecommons.org/licenses/by/3.0/","  We consider the agegraphic models of dark energy in a braneworld scenario
with brane-bulk energy exchange. We assume that the adiabatic equation for the
dark matter is satisfied while it is violated for the agegraphic dark energy
due to the energy exchange between the brane and the bulk. Our study shows that
with the brane-bulk interaction, the equation of state parameter of agegraphic
dark energy on the brane, $w_D$, can have a transition from normal state where
$w_D >-1 $ to the phantom regime where $w_D <-1 $, while the effective equation
of state for dark energy always satisfies $w^{\mathrm{eff}}_D\geq-1$.
","[{""version"":""v1"",""created"":""Sun, 9 Aug 2009 04:55:03 GMT""},{""version"":""v2"",""created"":""Sat, 6 Feb 2010 11:31:09 GMT""}]","2010-04-29"
"0908.1215","Xiaoguang Xu","X. G. Xu, D. L. Zhang, X. Q. Li, J. Bao, Y. Jiang","Synthetic antiferromagnet with Heusler alloy Co2FeAl ferromagnetic
  layers","12 pages, 6 figures",,"10.1063/1.3271352",,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Heusler alloy Co2FeAl was employed as ferromagnetic layers in
Co2FeAl/Ru/Co2FeAl synthetic antiferromagnet structures. The experimental
results show that the structure with a Ru thickness of 0.45 nm takes on
strongly antiferromagnetic coupling, which maintains up to 150 oC annealing for
1 hour. The structure has a very low saturation magnetization Ms of 425 emu/cc,
a low switching field Hsw of 4.3 Oe and a high saturation field Hs of 5257 Oe
at room temperature, which are favorable for application in ultrahigh density
magnetic read heads or other magnetic memory devices. XRD study testifies that
the as-deposited Co2FeAl film is in B2 phase. Therefore Heusler alloys can be
used to fabricate SyAF and it is possible to make ""all-Heusler"" spin-valves or
magnetic tunneling junctions with better magnetic switching properties and high
magnetoresistance.
","[{""version"":""v1"",""created"":""Sun, 9 Aug 2009 05:07:10 GMT""}]","2015-05-13"
"0908.1216","Du\v{s}an Repov\v{s}","Maxim V. Balashov and Du\v{s}an Repov\v{s}","Uniform convexity and the splitting problem for selections",,"J. Math. Anal. Appl. 360:1 (2009), 307-316","10.1016/j.jmaa.2009.06.045",,"math.GN math.FA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We continue to investigate cases when the Repov\v{s}-Semenov splitting
problem for selections has an affirmative solution for continuous set-valued
mappings. We consider the situation in infinite-dimensional uniformly convex
Banach spaces. We use the notion of Polyak of uniform convexity and modulus of
uniform convexity for arbitrary convex sets (not necessary balls). We study
general geometric properties of uniformly convex sets. We also obtain an
affirmative solution of the splitting problem for selections of certain
set-valued mappings with uniformly convex images.
","[{""version"":""v1"",""created"":""Sun, 9 Aug 2009 12:31:06 GMT""}]","2009-08-11"
"0908.1217","Ihor Lubashevsky","Ihor Lubashevsky and Natalia Plawinska","Mathematical formalism of physics of systems with motivation","25 pages, 4 pictures",,,,"physics.soc-ph physics.gen-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The paper discusses fundamental problems in mathematical description of
social systems based on physical concepts, with so-called statistical social
systems being the main subject of consideration. Basic properties of human
beings and human societies that distinguish social and natural systems from
each other are listed to make it clear that individual mathematical formalism
and physical notions should be developed to describe such objects rather then
can be directly inherited from classical mechanics and statistical physics. As
a particular example systems with motivation are considered. Their
characteristic features are analyzed individually and the appropriate
mathematical description is proposed. Finally the paper concludes that the
basic elements necessary for describing statistical social systems or, more
rigorously, systems with motivation are available or partly developed in modern
physics and applied mathematics.
","[{""version"":""v1"",""created"":""Sun, 9 Aug 2009 07:34:37 GMT""},{""version"":""v2"",""created"":""Fri, 8 Apr 2011 08:27:51 GMT""}]","2011-04-11"
"0908.1218","Sefi Ladkani","Sefi Ladkani","Categorification of a linear algebra identity and factorization of Serre
  functors","18 pages; Minor changes, references added, new Section 2.7","Mathematische Zeitschrift 285 (2017), 879-896","10.1007/s00209-016-1731-9",,"math.RT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We provide a categorical interpretation of a well-known identity from linear
algebra as an isomorphism of certain functors between triangulated categories
arising from finite dimensional algebras.
  As a consequence, we deduce that the Serre functor of a finite dimensional
triangular algebra A has always a lift, up to shift, to a product of suitably
defined reflection functors in the category of perfect complexes over the
trivial extension algebra of A.
","[{""version"":""v1"",""created"":""Sun, 9 Aug 2009 08:56:06 GMT""},{""version"":""v2"",""created"":""Mon, 15 Mar 2010 19:04:56 GMT""}]","2019-03-12"
"0908.1219","Johann Cigler","Johann Cigler","q-Fibonacci polynomials and q-Genocchi numbers",,,,,"math.CO math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We show that Genocchi and Bernoulli numbers are closely related to Fibonacci
polynomials and derive some q-analogues.
","[{""version"":""v1"",""created"":""Sun, 9 Aug 2009 08:51:50 GMT""},{""version"":""v2"",""created"":""Fri, 14 Aug 2009 08:30:08 GMT""},{""version"":""v3"",""created"":""Sun, 20 Sep 2009 06:40:52 GMT""},{""version"":""v4"",""created"":""Tue, 30 Nov 2010 13:38:49 GMT""}]","2010-12-01"
"0908.1220","R Doomun","Maher Ben Jemaa, Maryam Kallel Zouari, Bachar Zouari","A new approach to services differentiation between mobile terminals of a
  wireless LAN","8 Pages, IEEE Format, International Journal of Computer Science and
  Information Security, IJCSIS 2009, ISSN 1947 5500, Impact Factor 0.423","International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 3, No. 1, July 2009, USA",,"ISSN 1947 5500","cs.NI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This study aims to identify the advantages and disadvantages of several
mechanisms for service differentiation in mobile terminals of a wireless LAN to
establish a more better and more optimal. At the end of the analysis of
available approaches for the quality of service of the IEEE 802.11 standard,
the objective of this paper is to suggest a new method named DF-DCF
Differentiated Frame DCF. The performance of the suggested method in a Network
Simulator (NS) environment allowed its validation through a set of testing and
simulation scenarios. Simulation results have shown that the DF-DCF method is
better suited for mobile nodes in a wireless communication network.
","[{""version"":""v1"",""created"":""Sun, 9 Aug 2009 10:22:09 GMT""}]","2009-08-11"
"0908.1221","Tao Zhou","Xiaopu Han, Qiang Hao, Binghong Wang, Tao Zhou","Origin of the Scaling Law in Human Mobility: Hierarchical Organization
  of Traffic Systems","6 figures, 4 pages","Physical Review E 83 (2011) 036117","10.1103/PhysRevE.83.036117",,"physics.data-an physics.soc-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Uncovering the mechanism leading to the scaling law in human trajectories is
of fundamental importance in understanding many spatiotemporal phenomena. We
propose a hierarchical geographical model to mimic the real traffic system,
upon which a random walker will generate a power-law travel displacement
distribution with exponent -2. When considering the inhomogeneities of cities'
locations and attractions, this model reproduces a power-law displacement
distribution with an exponential cutoff, as well as a scaling behavior in the
probability density of having traveled a certain distance at a certain time.
Our results agree very well with the empirical observations reported in [D.
Brockmann et al., Nature 439, 462 (2006)].
","[{""version"":""v1"",""created"":""Sun, 9 Aug 2009 10:25:27 GMT""},{""version"":""v2"",""created"":""Sun, 16 Aug 2009 12:02:18 GMT""}]","2015-05-13"
"0908.1222","Rajesh Ramachandran","R Rajesh and Vinod Sharma","Distributed Joint Source-Channel Coding for Functions over a Multiple
  Access Channel","7 Pages, 2 Figures. To Appear in IEEE GLOBECOM, 2009",,,,"cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we provide sufficient conditions for lossy transmission of
functions of correlated data over a multiple access channel (MAC). The
conditions obtained can be shown as generalized version of Yamamoto's result.
We also obtain efficient joint source-channel coding schemes for transmission
of discrete and continuous alphabet sources to recover the function values.
  Keywords: Joint source-channel coding, Graph coloring, Lipschitz functions,
Correlated sources.
","[{""version"":""v1"",""created"":""Sun, 9 Aug 2009 10:34:24 GMT""}]","2009-08-11"
"0908.1223","Rajesh Ramachandran","R Rajesh and Vinod Sharma","Joint Source-Channel Coding over a Fading Multiple Access Channel with
  Partial Channel State Information","7 Pages, 3 figures. To Appear in IEEE GLOBECOM, 2009",,,,"cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we address the problem of transmission of correlated sources
over a fast fading multiple access channel (MAC) with partial channel state
information available at both the encoders and the decoder. We provide
sufficient conditions for transmission with given distortions. Next these
conditions are specialized to a Gaussian MAC (GMAC). We provide the optimal
power allocation strategy and compare the strategy with various levels of
channel state information.
  Keywords: Fading MAC, Power allocation, Partial channel state information,
Correlated sources.
","[{""version"":""v1"",""created"":""Sun, 9 Aug 2009 10:40:59 GMT""}]","2009-08-11"
"0908.1224","Sanjeev Gautam","Sanjeev Gautam, S. Kumar, P. Thakur, K. H. Chae, Ravi Kumar, and C. G.
  Lee","Electronic structure studies of Fe- ZnO nanorods by x-ray absorption
  fine structure","7 pages, 5 figures, 2 tables, regular article","J.Phys. D: Appl. Phys. 42 (2009) 175406","10.1088/0022-3727/42/17/175406","KIST-2V01450","cond-mat.mtrl-sci cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We report the electronic structure studies of well characterized
polycrystalline Zn_{1-x}Fe_xO (x = 0.0, 0.01, 0.03, and 0.05) nanorods
synthesized by a co-precipitation method through x-ray absorption fine
structure (XAFS). X-ray diffraction (XRD) reveals that Fe doped ZnO
crystallizes in a single phase wurtzite structure without any secondary phase.
  From the XRD pattern, it is observed that peak positions shift towards lower
2\theta value with Fe doping. The change in the peak positions with increase in
Fe contents clearly indicates that Fe ions are replacing Zn ions in the ZnO
matrix. Linear combination fittings (LCF) at Fe K-edge demonstrate that Fe is
in mixed valent state (Fe3+/Fe2+) with a ratio of ~ 7:3 (Fe3+:Fe2+). XAFS data
is successfully fitted to wurtzite structure using IFEFFIT and Artemis. The
results indicate that Fe substitutes Zn site in the ZnO matrix in tetrahedral
symmetry.
","[{""version"":""v1"",""created"":""Sun, 9 Aug 2009 11:02:10 GMT""}]","2011-11-22"
"0908.1225","Urs Gerber","U. Gerber, C. P. Hofmann, F. Kampfer, U.-J. Wiese","Microscopic Model versus Systematic Low-Energy Effective Field Theory
  for a Doped Quantum Ferromagnet","34 pages, 1 figure","Phys.Rev.B81:064414,2010","10.1103/PhysRevB.81.064414",,"cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider a microscopic model for a doped quantum ferromagnet as a test
case for the systematic low-energy effective field theory for magnons and
holes, which is constructed in complete analogy to the case of quantum
antiferromagnets. In contrast to antiferromagnets, for which the effective
field theory approach can be tested only numerically, in the ferromagnetic case
both the microscopic and the effective theory can be solved analytically. In
this way the low-energy parameters of the effective theory are determined
exactly by matching to the underlying microscopic model. The low-energy
behavior at half-filling as well as in the single- and two-hole sectors is
described exactly by the systematic low-energy effective field theory. In
particular, for weakly bound two-hole states the effective field theory even
works beyond perturbation theory. This lends strong support to the quantitative
success of the systematic low-energy effective field theory method not only in
the ferromagnetic but also in the physically most interesting antiferromagnetic
case.
","[{""version"":""v1"",""created"":""Sun, 9 Aug 2009 11:32:16 GMT""}]","2013-05-29"
"0908.1226","Lorenzo Iorio","Lorenzo Iorio","""Imprinting"" in General Relativity Tests?","LaTex2e, 4 pages, no figures, no tables, 3 references. Submitted to
  Proceedings of the 1st Galileo-Xu Guangqi Meeting, Shangai, October 26-30
  2009","Int. J. Mod. Phys. D20:1945-1948,2011","10.1142/S0218271811019980",,"gr-qc astro-ph.EP hep-ph physics.geo-ph physics.space-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate possible a-priori ""imprinting"" of general relativity itself on
spaceraft-based tests of it. We deal with some performed or proposed time-delay
ranging experiments in the Sun's gravitational field. The ""imprint"" of general
relativity on the Astronomical Unit and the solar gravitational constant
GM_\odot, not solved for in the so far performed spacecraft-based time-delay
tests, may induce an a-priori bias of the order of 10^-6 in typical solar
system ranging experiments aimed to measuring the space curvature PPN parameter
\gamma. It is too small by one order of magnitude to be of concern for the
performed Cassini experiment, but it would affect future planned or proposed
tests aiming to reach a 10^-7-10^-9 accuracy in determining \gamma.
","[{""version"":""v1"",""created"":""Sun, 9 Aug 2009 11:18:15 GMT""},{""version"":""v2"",""created"":""Thu, 20 Aug 2009 13:43:59 GMT""},{""version"":""v3"",""created"":""Fri, 21 Aug 2009 22:49:39 GMT""},{""version"":""v4"",""created"":""Wed, 30 Dec 2009 15:08:12 GMT""}]","2011-09-29"
"0908.1227","Kin Ming Hui","Kin Ming Hui","Quenching behaviour of a nonlocal parabolic MEMS equation","13 pages",,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We obtain upper bounds for the quenching time of the solutions of the
nonlocal parabolic MEMS equation $u_t=\Delta
u+\lam/(1-u)^2(1+\chi\int_{\Omega}1/(1-u) dx)^2$ in $\Omega\times (0,\infty)$,
$u=0$ on $\1\Omega\times (0,\infty)$, $u(x,0)=u_0$ in $\Omega$, when $\lambda$
is large. We prove the compactness of the quenching set under a mild condition
on the initial data. When $\Omega=B_R$ and $u_0$ is radially symmetric and
monotone decreasing in $0\le r\le R$, we prove that the point $x=0$ is the only
possible quenching set. When $u_0$ also satisfies some strict concavity
assumption, we prove that for any $\beta\in (2,3)$ the solution satisfies
$1-u(x,t)\ge C|x|^{\frac{2}{\beta}}$ for some constant $C>0$ and we also obtain
the quenching time estimate in this case.
","[{""version"":""v1"",""created"":""Sun, 9 Aug 2009 11:20:09 GMT""},{""version"":""v2"",""created"":""Tue, 16 Mar 2010 00:22:04 GMT""}]","2010-03-17"
"0908.1228","Ido Regev","Valery Ilyin, Itamar Procaccia, Ido Regev and Yair Shokef","Randomness-Induced Redistribution of Vibrational Frequencies in
  Amorphous Solids","14 pages, 22 figures","Phys. Rev. B 80, 174201 (2009)","10.1103/PhysRevB.80.174201",,"cond-mat.mtrl-sci cond-mat.stat-mech","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Much of the discussion in the literature of the low frequency part of the
density of states of amorphous solids was dominated for years by comparing
measured or simulated density of states to the classical Debye model. Since
this model is hardly appropriate for the materials at hand, this created some
amount of confusion regarding the existence and universality of the so- called
``Boson Peak'' which results from such comparisons. We propose that one should
pay attention to the different roles played by different aspects of disorder,
the first being disorder in the interaction strengths, the second positional
disorder, and the third coordination disorder. These have different effects on
the low-frequency part of the density of states. We examine the density of
states of a number of tractable models in one and two dimensions, and reach a
clearer picture of the softening and redistribution of frequencies in such
materials. We discuss the effects of disorder on the elastic moduli and the
relation of the latter to frequency softening, reaching the final conclusion
that the Boson peak is not universal at all.
","[{""version"":""v1"",""created"":""Sun, 9 Aug 2009 11:25:36 GMT""}]","2009-11-04"
"0908.1229","Klaus Bering","Klaus Bering and Harald Grosse","On Batalin-Vilkovisky Formalism of Non-Commutative Field Theories","20 pages, LaTeX. v2: minor corrections. v3: Added an Appendix about
  Harish-Chandra-Itzykson-Zuber integrals. v4: Added References","Eur.Phys.J.C68:313-324,2010","10.1140/epjc/s10052-010-1323-5",,"hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We apply the BV formalism to non-commutative field theories, introduce BRST
symmetry, and gauge-fix the models. Interestingly, we find that treating the
full gauge symmetry in non-commutative models can lead to reducible gauge
algebras. As one example we apply the formalism to the Connes-Lott two-point
model. Finally, we offer a derivation of a superversion of the
Harish-Chandra-Itzykson-Zuber integral.
","[{""version"":""v1"",""created"":""Sun, 9 Aug 2009 11:27:17 GMT""},{""version"":""v2"",""created"":""Fri, 18 Sep 2009 08:48:45 GMT""},{""version"":""v3"",""created"":""Wed, 27 Jan 2010 18:37:39 GMT""},{""version"":""v4"",""created"":""Tue, 9 Feb 2010 17:14:46 GMT""}]","2014-11-20"
"0908.1230","Yi Wang","Buyang Li, Weiwei Sun, Yi Wang","Global existence of weak solution to the heat and moisture transport
  system in fibrous porous media","19 pages",,,,"math.AP","http://creativecommons.org/licenses/by-nc-sa/3.0/","  This paper is concerned with theoretical analysis of a heat and moisture
transfer model arising from textile industries, which is described by a
degenerate and strongly coupled parabolic system. We prove the global (in time)
existence of weak solution by constructing an approximate solution with some
standard smoothing. The proof is based on the physcial nature of gas
convection, in which the heat (energy) flux in convection is determined by the
mass (vapor) flux in convection.
","[{""version"":""v1"",""created"":""Sun, 9 Aug 2009 12:31:17 GMT""}]","2009-08-11"
"0908.1231","Chris Fields","Chris Fields","Information contents and architectural requirements of observer ""ready""
  states","17 pages, supports principal claim of arXiv:0906.2306; v2 complete
  re-write to improve notation, emphasize architectural issues, define POVMs
  and improve proof of Born rule; v3 revisions to improve clarity; result that
  observational outcomes are virtual-machine states not physical states made
  more explicit",,,,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A functional analysis of the task of observing multiple macroscopic quantum
systems over an extended period of time and then reporting the accumulated
results is used to investigate the information that must be encoded in the
""ready"" state |O^r> of any finite, macroscopic observer O capable of performing
this task. Decoherence considerations show that this task can be considered as
involving local observations under classical conditions (LOCC), allowing the
use of classical automata theory to define a minimal observer. It is shown that
such a minimal observer must implement a functional architecture equivalent to
a classical Turing machine and must encode in |O^r> a classical specification
of the complete set of reportable apparatus states. The observation task is
then re-characterized employing an explicit model of such a minimal observer,
and it is shown that both the assumption that external systems have
well-defined boundaries against the environment and the assumption of
decoherence are unnecessary for the characterization of measurements made by a
minimal observer. It is shown that the observables available to a minimal
observer are positive operator-valued measures (POVMs) and that the measurement
results reported by a minimal observer comply with the Born rule. The
differences in underlying physical assumptions between this ""systems-free""
treatment of observation and that traditionally employed in analyses of quantum
measurement and quantum communication are discussed.
","[{""version"":""v1"",""created"":""Sun, 9 Aug 2009 13:02:30 GMT""},{""version"":""v2"",""created"":""Mon, 31 Jan 2011 17:03:15 GMT""},{""version"":""v3"",""created"":""Sat, 5 Mar 2011 13:53:40 GMT""}]","2011-03-08"
"0908.1232","Tian De Cao","Tian De Cao","Multiferroics seen from theoretic derivation of a tight binding model","4pages,strong correlated systems",,,,"physics.gen-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  One presented some lattice models, while the theoretic derivation has not
been found, and the importance of correlation effects has to be emphasized. On
the basis of the non-relativistic Hamiltonian from the Dirac equation, we
derive in detail a tight binding model. We find that both ferromagnetism and
ferroelectricity are from the correlation effect between electrons, and
magnetic and electric orders are strongly coupled due to the spin-orbit
interaction.
","[{""version"":""v1"",""created"":""Sun, 9 Aug 2009 13:08:47 GMT""},{""version"":""v2"",""created"":""Wed, 12 Aug 2009 07:09:43 GMT""},{""version"":""v3"",""created"":""Mon, 24 Aug 2009 23:03:36 GMT""}]","2009-08-25"
"0908.1233","Yuri Bilu","Yuri Bilu, Marco Strambi, Andrea Surroca","Quantitative Chevalley-Weil theorem for curves","version 4: minor inaccuracies in Lemma 3.4 and Proposition 5.2
  corrected",,,,"math.NT math.AG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The classical Chevalley-Weil theorem asserts that for an \'etale covering of
projective varieties over a number field K, the discriminant of the field of
definition of the fiber over a K-rational point is uniformly bounded. We obtain
a fully explicit version of this theorem in dimension 1.
","[{""version"":""v1"",""created"":""Sun, 9 Aug 2009 13:19:29 GMT""},{""version"":""v2"",""created"":""Tue, 13 Dec 2011 01:47:11 GMT""},{""version"":""v3"",""created"":""Fri, 23 Dec 2011 01:31:15 GMT""},{""version"":""v4"",""created"":""Fri, 9 Nov 2012 00:49:15 GMT""}]","2012-11-12"
"0908.1234","Ismael Rafols","Ismael Rafols, Patrick van Zwanenberg, Molly Morgan, Paul Nightingale,
  Adrian Smith","The missing link in nanomaterials governance: industrial dynamics and
  downstream policies","14 pages, 1 figure",,,,"physics.soc-ph cond-mat.mtrl-sci cond-mat.other","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this article we explore the analytical and policy implications of widening
the governance of nanomaterials from the focus on risk regulation to a broader
focus on the governance of innovation. To do this, we have analysed the impact
of industrial activities on nanotechnology governance, while previous studies
have concentrated on risk appraisal, public perceptions, public engagement,
regulatory frameworks and related policies. We argue that the specific
characteristics of the industrial dynamics of nanomaterials - flexibility in
applications and distributed innovation - have important implications for
innovation governance as they limit and enable different interventions to
attempt to shape technology. Flexibility and distributedness exacerbate the
difficulties of directly controlling or shaping the directions of nanomaterials
innovation. In particular, the potential for public policy leverage is hindered
by the bottom-up nature of governance resulting from the multiplicity of
innovation sites. Under these conditions, we argue that the framing of policies
for nanomaterials governance needs to be broadened. The prevailing emphasis on
policy initiatives upstream, while commendable, should be complemented with
broader downstream policies, such as renewable energy procurement or
regulations in housing, in order to modulate technological development towards
socially desirable goals.
","[{""version"":""v1"",""created"":""Sun, 9 Aug 2009 13:49:02 GMT""}]","2014-12-23"
"0908.1235","Jelena Petrovic","Jelena Petrovic","Multimessenger search for point sources: ultra-high energy cosmic rays
  and neutrinos",,,,,"astro-ph.IM astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The origin of ultra-high energy cosmic rays (UHECRs) and neutrinos is still a
mystery. Hadronic acceleration theory suggests that they should originate in
the same sources (astrophysical or cosmological), together with gamma-rays.
While gamma-rays have been linked to astrophysical sources, no point source of
UHECRs or neutrinos have been found so far. In this paper, the multimessenger
combination of UHECRs and neutrinos as a new approach to the high energy
particle point source search is suggested. A statistical method for
cross-correlation of UHECR and neutrino data sets is proposed. By obtaining the
probability density function of number of neutrino events within chosen angular
distance from observed UHECRs, the number of neutrino events in the vicinity of
observed UHECRs, necessary to claim a discovery with a chosen significance, can
be calculated. Different angular distances (bin sizes) are considered due to
the unknown deflection of cosmic rays in galactic and intergalactic magnetic
fields. Possible observed correlation of the arrival directions of UHECRs and
neutrinos would provide a strong indication of hadronic acceleration theory.
Correlation of both types of messengers with the location of certain sets of
observed astrophysical objects would indicate sites of acceleration. Any
systematic offset in arrival directions between UHECRs and neutrinos may shed
more light on magnetic field deflection of cosmic rays.
","[{""version"":""v1"",""created"":""Sun, 9 Aug 2009 13:51:22 GMT""},{""version"":""v2"",""created"":""Wed, 2 Sep 2009 11:37:02 GMT""},{""version"":""v3"",""created"":""Fri, 2 Oct 2009 13:57:27 GMT""}]","2009-10-02"
"0908.1236","Juan Zhang","Juan Zhang (1), Qiang Yuan (1), Xiao-Jun Bi (1,2) ((1) IHEP, CAS,
  China, (2) Center for High Energy Physics, Peking University)","Galactic diffuse gamma rays --- recalculation based on the new
  measurements of cosmic electron spectrum","23pages,7figures; Fermi diffuse gamma ray data are used, the
  corresponding discussion and figs are changed, sections are reorganized and a
  new section is added. ApJ in press","Astrophys.J.720:9-19,2010","10.1088/0004-637X/720/1/9",,"astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this work, we revisit the all-sky Galactic diffuse $\gamma$-ray emission
taking into account the new measurements of cosmic ray electron/positron
spectrum by PAMELA, ATIC and Fermi, which show excesses of cosmic
electrons/positrons beyond the expected fluxes in the conventional model. Since
the origins of the extra electrons/positrons are not clear, we consider three
different scenarios to account for the excesses: the astrophysical sources such
as the Galactic pulsars, dark matter decay and annihilation. Further, new
results from Fermi-LAT of the (extra-)Galactic diffuse $\gamma$-ray are
adopted.
  The background cosmic rays without the new sources give lower diffuse
$\gamma$ rays compared to Fermi-LAT observation, which is consistent with
previous analysis. The scenario with astrophysical sources predicts diffuse
$\gamma$-rays with little difference with the background. The dark matter
annihilation models with $\tau^{\pm}$ final state are disfavored by the Fermi
diffuse $\gamma$-ray data, while there are only few constraints on the decaying
dark matter scenario. Furthermore, these is always a bump at higher energies
($\sim$ TeV) of the diffuse $\gamma$-ray spectra for the dark matter scenarios
due to final state radiation. Finally we find that the Fermi-LAT diffuse
$\gamma$-ray data can be explained by simply enlarging the normalization of the
electron spectrum without introduce any new sources, which may indicate that
the current constraints on the dark matter models can be much stronger given a
precise background estimate.
","[{""version"":""v1"",""created"":""Sun, 9 Aug 2009 14:41:32 GMT""},{""version"":""v2"",""created"":""Sun, 4 Jul 2010 09:04:15 GMT""}]","2014-11-20"
"0908.1237","B. S. Lakshmi","B. S. Lakshmi","On a Modified Klein Gordon Equation","5 pages, TeX",,,,"physics.gen-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider a modified Klein-Gordon equation that arises at ultra high
energies. In a suitable approximation it is shown that for the linear potential
which is of interest in quark interactions, their confinement for example,we
get solutions that mimic the Harmonic oscillator energy levels, surprisingly.
An equation similar to the beam equation is obtained in the process.
","[{""version"":""v1"",""created"":""Sun, 9 Aug 2009 14:45:36 GMT""}]","2009-08-11"
"0908.1238","Yafis Barlas","Yafis Barlas and Kun Yang","Non-Fermi Liquid behavior in Neutral Bilayer Graphene","published version","Phys. Rev. B 80, 161408(R) (2009)","10.1103/PhysRevB.80.161408",,"cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We calculate the density-density response function and electron self-energy
for undoped bilayer graphene, within the Random Phase Approximation (RPA). We
show that the quasiparticle decay rate scales linearly with the quasiparticle
energy, and quasiparticle weight vanishes logarithmically in the low-energy
limit, indicating non-Fermi liquid behavior. This is a consequence of the
absence of a Fermi surface for neutral bilayer graphene and corresponding
larger phase space available for scattering processes. Experimental
consequences of our results as well as their differences from those of
single-layer graphene are discussed.
","[{""version"":""v1"",""created"":""Sun, 9 Aug 2009 15:00:44 GMT""},{""version"":""v2"",""created"":""Fri, 23 Oct 2009 15:25:15 GMT""}]","2009-10-23"
"0908.1239","Meilland Anthony","Anthony Meilland (MPIfr), Philippe Stee (FIZEAU), Olivier Chesneau
  (FIZEAU), Carol Jones","VLTI/MIDI observations of 7 classical Be stars",,,"10.1051/0004-6361/200911960",,"astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We measured the mid-infrared extension of the gaseous disk surrounding seven
Be stars in order to constrain the geometry of their circumstellar environments
and to try to infer physical parameters characterizing these disks. We used the
VLTI/MIDI instrument with baselines up to 130 m to obtain an angular resolution
of about 15 mas in the N band and compared our results with previous K band
measurements obtained with the VLTI/AMBER instrument and/or the CHARA
interferometer. We obtained one calibrated visibility measurement for each of
the four stars, p Car, zeta Tau, kappa CMa, and alpha Col, two for delta Cen
and beta CMi, and three for alpha Ara. Almost all targets remain unresolved
even with the largest VLTI baseline of 130m, evidence that their circumstellar
disk extension is less than 10 mas. The only exception is alpha Ara, which is
clearly resolved and well-fitted by an elliptical envelope with a major axis
a=5.8+-0.8mas and an axis ratio a/b=2.4+-1 at 8 microns. This extension is
similar to the size and flattening measured with the VLTI/AMBER instrument in
the K band at 2 microns. The size of the circumstellar envelopes for these
classical Be stars does not seem to vary strongly on the observed wavelength
between 8 and 12microns. Moreover, the size and shape of Alpha Ara's disk is
almost identical at 2, 8, and 12microns.
","[{""version"":""v1"",""created"":""Sun, 9 Aug 2009 15:15:21 GMT""}]","2015-05-13"
"0908.1240","C. Douglas Haessig","C. Douglas Haessig and Antonio Rojas-Leon","L-functions of symmetric powers of the generalized Airy family of
  exponential sums: ell-adic and p-adic methods","This paper has been withdrawn by the authors. This paper has been
  updated and split into two papers",,,,"math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  For \psi a nontrivial additive character on the finite field F_q, the map t
\mapsto \sum_{x \in F_q} \psi(f(x)+tx) is the Fourier transform of the map t
\mapsto \psi(f(t))$. As is well-known, this has a cohomological interpretation,
producing a continuous ell-adic Galois representation. This paper studies the
L-function attached to the k-th symmetric power of this representation using
both ell-adic and p-adic methods. Using ell-adic techniques, we give an
explicit formula for the degree of this L-function and determine the complex
absolute values of its roots. Using p-adic techniques, we study the p-adic
absolute values of the roots.
","[{""version"":""v1"",""created"":""Sun, 9 Aug 2009 15:18:53 GMT""},{""version"":""v2"",""created"":""Mon, 2 Aug 2010 20:44:29 GMT""}]","2010-08-04"
